{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import utils_modified; reload(utils_modified)\n",
    "from utils_modified import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Embedding, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.engine.topology import Merge\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers.convolutional import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = '../data/imdb/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "idx = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'a', 'of', 'to', 'is', 'br', 'in', 'it', 'i']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_arr = sorted(idx, key=idx.get)\n",
    "idx_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in idx.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('to', 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "(idx2word[n], idx[idx2word[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = get_file('imdb_full.pkl',\n",
    "                origin='https://s3.amazonaws.com/text-datasets/imdb_full.pkl',\n",
    "                md5_hash='d091312047c43cf9e4e38fef92437263')\n",
    "f = open(path, 'rb')\n",
    "(x_train, labels_train), (x_test, labels_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 433, 149)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train contains lists of variable length were words are represented by indices\n",
    "len(x_train[0]), len(x_train[1]), len(x_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrds = [idx2word[n] for n in x_train[0]]\n",
    "' '.join(wrds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 2500\n",
    "#wvect_dims = 32\n",
    "maxlen = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def paddedset(orig_set):\n",
    "    adj_set = [[min(n,vocab_size-1) for n in sq] for sq in orig_set]\n",
    "    return pad_sequences(adj_set, maxlen=maxlen, dtype='int32', padding='pre', truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_pad = paddedset(x_train)\n",
    "x_test_pad = paddedset(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "[23022, 309, 6, 3, 1069, 209, 9, 2175]\n",
      "[2499, 309, 6, 3, 1069, 209, 9, 2175]\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[0]))\n",
    "print(x_train[0][0:8])\n",
    "print([n for n in x_train_pad[0] if n>0][0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../data/glove/glove.6B.100d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1095db4fea83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mGLOVE_DIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../data/glove/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0membeddings_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGLOVE_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'glove.6B.100d.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../data/glove/glove.6B.100d.txt'"
     ]
    }
   ],
   "source": [
    "# Load GloVe embedding weights with :\n",
    "#     wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "\n",
    "GLOVE_DIR = '../data/glove/'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2499"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newwords = embeddings_index.keys()\n",
    "count = 0\n",
    "for i in range(1,vocab_size):\n",
    "    if not(idx2word[i] in newwords):\n",
    "        count+=1\n",
    "        #print(idx2word[i])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "#for word, i in idx2word[i]:#word_index.items():\n",
    "for i in range(1,vocab_size):\n",
    "    word = idx2word[i]\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# architecture defined here :\n",
    "#     https://quid.com/feed/how-quid-uses-deep-learning-with-small-data\n",
    "graph_in = Input(shape=(maxlen, EMBEDDING_DIM))\n",
    "convs = []\n",
    "for w in range(1,4): # the convolution window width\n",
    "    conv = Convolution1D(nb_filter=300,\n",
    "                         filter_length=w,\n",
    "                         border_mode='valid',\n",
    "                         activation='relu',\n",
    "                         subsample_length=1)(graph_in)\n",
    "    pool = MaxPooling1D(pool_length=2)(conv)\n",
    "    flatten = Flatten()(pool)\n",
    "    convs.append(flatten)\n",
    "out = Merge(mode='concat')(convs)\n",
    "graph = Model(input=graph_in, output=out)\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocab_size, EMBEDDING_DIM, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "model3.add(graph)\n",
    "model3.add(Dense(300))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dense(100))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dense(1))\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "model3.compile(optimizer=Adam(), loss='binary_crossentropy') # WARNING : metrics=['accuracy'] fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model3.fit(x_train_pad, labels_train, batch_size=100, nb_epoch=1, validation_data=(x_test_pad, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model3.predict(x_train_pad[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "cities = ['miami','boston','chicago','seattle','washington','atlanta',\n",
    "            'paris',\n",
    "            'london','manchester','liverpool',\n",
    "            'glasgow',\n",
    "            'dublin',\n",
    "            'berlin',\n",
    "            'moscow',\n",
    "            'madrid','barcelona',\n",
    "            'toronto','montreal',\n",
    "            'rome','vienna',\n",
    "            'tokyo','sydney',\n",
    "               ]\n",
    "cities = ['usa','france','germany','china','russia','italy','spain','sweden',\n",
    "          'vietnam','japan','australia','canada',\n",
    "         'greece','portugal','england','ireland','mexico','austria','egypt','brazil']\n",
    "#cities = ['usa','washington','france','paris','spain','madrid','germany','berlin','italy','rome','uk','london',\n",
    "#          'one','two','three','four','five','six','seven','eight','nine']\n",
    "tsnewords = []\n",
    "tsnewords.extend(embeddings_index.keys()[5:3000])\n",
    "tsnewords.extend(cities)\n",
    "X = np.array([embeddings_index[wrd] for wrd in tsnewords])\n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "T = model.fit_transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reload(sys) # important for labels\n",
    "sys.setdefaultencoding('utf8') # important for labels\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = T[-len(cities):,:]\n",
    "labels = cities\n",
    "\n",
    "plt.figure(figsize=(11,11))\n",
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "for label, x, y in zip(labels, data[:, 0], data[:, 1]):\n",
    "    plt.text(x,y,label, color=np.random.rand(3)*0.7,\n",
    "                 fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
