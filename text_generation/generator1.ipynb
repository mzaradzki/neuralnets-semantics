{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils_modified; reload(utils_modified)\n",
    "from utils_modified import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, Embedding, Activation, LSTM, merge, Flatten, Dropout, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "from keras.engine.topology import Merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers.convolutional import *\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n",
      "total chars: 85\n",
      "nb sequences: 200287\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()#.lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lag = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "Xs = []\n",
    "for l in range(lag):\n",
    "    cdat = [idx[i+l] for i in xrange(0, len(idx)-1-lag, lag)]\n",
    "    X = np.stack(cdat[:-3])\n",
    "    Xs.append(X)\n",
    "\n",
    "cdat = [idx[i+(l+1)] for i in xrange(0, len(idx)-1-lag, lag)]\n",
    "Y = np.stack(cdat[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = [Input(shape=(1,), dtype='int64') for i in range(lag)]\n",
    "\n",
    "E = Embedding(output_dim=50, input_dim=len(chars), input_length=1)\n",
    "\n",
    "Di = Dense(50, activation='relu')\n",
    "Dh = Dense(50, activation='relu', init='identity')\n",
    "\n",
    "#hidden = ... CONSTANT ZERO TENSOR IN KERAS ?\n",
    "\n",
    "e = Di(Flatten()(E(inputs[0])))\n",
    "hidden = e\n",
    "for i in range(1,lag):\n",
    "    e = Di(Flatten()(E(inputs[i])))\n",
    "    hidden = merge([e, Dh(hidden)], mode='sum')\n",
    "predictions = Dense(len(chars), activation='softmax')(hidden)\n",
    "\n",
    "model = Model(input=inputs, output=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "150221/150221 [==============================] - 18s - loss: 2.0809 - acc: 0.4002    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcaf0e8ec10>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit(Xs, to_categorical(Y,len(chars)), nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_top_next(inp):\n",
    "    idxs = [char_indices[c] for c in inp][-lag:]\n",
    "    ps = model.predict([np.array([i]) for i in idxs])\n",
    "    probas = ps[0]/np.sum(ps)\n",
    "    for i in range(5):\n",
    "        index = np.random.choice(range(len(chars)), size=None, replace=True, p=probas)\n",
    "        print(inp+chars[index])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "herseld\n",
      "herself\n",
      "herself\n",
      "hersel,\n",
      "hersel \n",
      "\n",
      "himself\n",
      "himseld\n",
      "himself\n",
      "himself\n",
      "himself\n",
      "\n",
      "mora \n",
      "morau\n",
      "morat\n",
      "mora \n",
      "mora \n",
      "\n",
      "morall\n",
      "morali\n",
      "moraln\n",
      "moral \n",
      "moraly\n",
      "\n",
      "moralit\n",
      "morali \n",
      "moralie\n",
      "moralit\n",
      "moralid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_top_next('hersel')\n",
    "show_top_next('himsel')\n",
    "show_top_next('mora')\n",
    "show_top_next('moral')\n",
    "show_top_next('morali')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
